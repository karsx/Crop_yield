import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.preprocessing import StandardScaler

# Your dataset
data = np.array([[1230, 1230, 1230, 1230, 1230, 1230],
    [480, 60, 36, 70, 20, 18],
    [1250,	75,	29,	78,	22,	19],	
    [450,	65,	35,	70,	19,	18],	
[1200,	80,	27,	79,	22,	19],	
[500,	70,	34,	74,	22,	16],	
[1275,	71,	28,	77,	21,	20],	
[425,	65,	37,	67,	18,	15],	
[1200,	77,	27,	78,	23,	20],	
[400,	50,	39,	60,	18,	15],	
[1280,	80,	26,	80,	24,	20],	
[415,	55,	38,	65,	19,	17],	
[1225,	79,	29,	79,	23,	20],	
[425,	50,	37,	65,	18,	19],	
[1250,	70,	24,	70,	22,	18],	
[400,	60,	39,	60,	18,	15],	
[1300,	80,	28,	80,	24,	20],	
[410,	55,	36,	65,	21,	16],
[1150,	77,	28,	76,	23,	20],	
[1200,	78,	27,	78,	23,	19],	
[410,	50,	37,	59,	19,	15],
[1280,	76,	26,	75,	24,	19],	
[425,	55,	38,	65,	19,	17],	
[1225,	73,	29,	73,	23,	20],	
[450,	50,	37,	65,	18,	19],	
[1250,	70,	24,	70,	22,	18],
[400,	60,	39,	60,	18,	15],
[1250,	80,	28,	80,	24,	20],	
[405,	55,	36,	60,	21,	16],	
[1200,	72,	29,	73,	21,	19],	
[1150,	80,	26,	75,	21,	20],	
[475,	55,	39,	61,	18,	16],	
[1275,	76,	26,	75,	24,	19],	
[450,	55,	38,	65,	19,	17],	
[1200,	73,	29,	73,	23,	20],	
[500,	50,	37,	65,	18,	19],	
[1300,	70,	24,	70,	22,	18],	
[425,	60,	39,	60,	18,	15],	
[1250,	75,	26,	75,	22,	19],
[440,	58,	37,	66,	22,	18],	
[1275,	78,	28,	77,	23,	21],
[405,	55,	36,	60,	21,	16],	
[1175,	78,	28,	75,	23,	22],
[410,	60,	39,	65,	18,	15],	
[1250,	80,	26,	78,	23,	19],
[460,	55,	38,	61,	20,	18],	
[1275,	76,	26,	75,	24,	19],	
[445,	60,	38,	68,	22,	18],	
[1220,	77,	29,	75,	22,	19],	
[450,	50,	37,	60,	18,	15],	
[1225,	79,	24,	79,	22,	19],	
[430,	65,	39,	65,	19,	16],	
[1275,	77,	27,	78,	21,	20],	
[400,	52,	38,	64,	19,	15],	
[1245,	78,	27,	78,	22,	19],	
[455,	58,	37,	61,	21,	18],	
[1280,	73,	28,	75,	24,	19],	
[475,	62,	37,	68,	22,	18],	
[1300,	79,	28,	77,	23,	19],	
[425,	55,	36,	65,	19,	15],	
[1175,	77,	25,	75,	22,	19],	
[425,	70,	39,	70,	20,	16],	
[1200,	75,	27,	79,	21,	20],	
[450,	56,	40,	67,	18,	15],
[1200,	75,	27,	76,	21,	19],	
[410,	55,	38,	68,	20,	16],
[1250,	75,	27,	75,	23,	20],	
[475,	60,	37,	63,	20,	18],	
[1225,	75,	29,	77,	23,	19],	
[455,	60,	38,	65,	20,	16],	
[1245,	77,	27,	75,	22,	20],	
[450,	59,	40,	67,	18,	16],	
[1200,	79,	27,	77,	23,	20],	
[475,	72,	36,	71,	21,	17],	
[1275,	77,	28,	76,	22,	19],	
[475,	58,	39,	68,	19,	16],	
[1300,	80,	28,	80,	24,	20],
[400,	50,	40,	60,	18,	15],	
[1175,	70,	28,	70,	22,	19],
[445,	65,	39,	65,	21,	19],	
[1200,	77,	29,	76,	22,	19],	
[450,	65,	38,	60,	20,	16],	
[1225,	75,	28,	79,	21,	19],	
[450,	65,	39,	70,	20,	19],
[1300,	76,	28,	77,	22,	20],	
[450,	70,	36,	72,	25,	18],
[1250,	77,	28,	76,	22,	19],	
[475,	60,	39,	70,	20,	17],	
[1200,	75,	28,	77,	23,	19],	
[410,	52,	40,	62,	19,	16],	
[1225,	75,	28,	75,	23,	20],	
[460,	60,	39,	60,	20,	16],	
[1150,	78,	29,	77,	21,	18],	
[475,	65,	38,	60,	20,	16],	
[1250,	77,	28,	78,	23,	20],	
[425,	60,	39,	65,	19,	17],	
[1220,	79,	28,	77,	23,	21],	
[480,	65,	36,	68,	21,	16],	
[1230,	80,	28,	80,	24,	20]
    
    # ... (rest of your dataset)
])

# Separate features (X) and target variable (y)
X = data[:, :-1]
y = data[:, -1]

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# XGBoost model
xgb_model = XGBRegressor(objective="reg:squarederror")
xgb_model.fit(X_train, y_train)

# AdaBoost model
ada_model = AdaBoostRegressor()
ada_model.fit(X_train, y_train)

# Predictions
y_pred_xgb = xgb_model.predict(X_test)
y_pred_ada = ada_model.predict(X_test)

# Evaluation
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)

mse_ada = mean_squared_error(y_test, y_pred_ada)
rmse_ada = np.sqrt(mse_ada)

r2_xgb = r2_score(y_test, y_pred_xgb)
r2_ada = r2_score(y_test, y_pred_ada)

print(f"XGBoost - Mean Squared Error: {mse_xgb}, RMSE: {rmse_xgb}, R^2 Score: {r2_xgb}")
print(f"AdaBoost - Mean Squared Error: {mse_ada}, RMSE: {rmse_ada}, R^2 Score: {r2_ada}")
